{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy, time\n",
    "import math\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold ,train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "df_train = pd.read_csv('./train_data.csv')\n",
    "df_test = pd.read_csv('./test_features.csv')\n",
    "print(df_train.shape)\n",
    "columns=list(df_train.columns)\n",
    "print(columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y=df_train['poi'] #目標欄位\n",
    "name = df_test['name'] \n",
    "df_train = df_train.drop(['name','poi'] , axis=1) \n",
    "columns.remove('name')\n",
    "columns.remove('poi')\n",
    "df_test = df_test.drop(['name'] , axis=1)\n",
    "df = pd.concat([df_train, df_test],sort=False) #資料一併做前處理\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 'director_fees', 'exercised_stock_options', 'expenses', 'long_term_incentive','restricted_stock', 'restricted_stock_deferred',  'total_payments', 'total_stock_value' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['BAXTER JOHN C'].loc[] = 300000\n",
    "#df['LAY KENNETH L'].loc = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 缺失值處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def na_num(df_data):\n",
    "    num = (df_data.isnull().sum()/len(df)).sort_values(ascending=False)\n",
    "    return num\n",
    "\n",
    "print(na_num(df)) #欄位缺失率\n",
    "\n",
    "#缺失值比率過高，先捨去欄位\n",
    "df = df.drop(['loan_advances'],axis=1)\n",
    "\n",
    "#類別缺失值處理，改以是否有信箱\n",
    "none_cols = ['email_address']\n",
    "for col in none_cols:\n",
    "    df[col]=df[col].isnull() \n",
    "    #df[col] = df[col].fillna(\"None\")\n",
    "\n",
    "#部分欄位缺失值填補0\n",
    "zero_cols = ['long_term_incentive', 'deferred_income','deferral_payments','director_fees',\\\n",
    "            'from_messages','to_messages','from_poi_to_this_person', 'from_this_person_to_poi',\\\n",
    "            'shared_receipt_with_poi',\\\n",
    "             'director_fees', 'exercised_stock_options', 'expenses', 'long_term_incentive','restricted_stock',\\\n",
    "             'restricted_stock_deferred', 'total_payments', 'total_stock_value' ]\n",
    "for col in zero_cols:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "#部分欄位缺失值填補眾數\n",
    "mod_cols = []\n",
    "for col in mod_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "#部分欄位缺失值填補平均數\n",
    "mean_cols = ['other','exercised_stock_options']\n",
    "for col in mean_cols:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "#部分欄位缺失值填補中位數\n",
    "med_cols = ['salary','bonus']\n",
    "for col in med_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "#確認缺失值填補是否完整\n",
    "print(na_num(df)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 離群值處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#離群值處理\n",
    "def remove_outlier(df):\n",
    "    for k in df.columns[1:]:\n",
    "        df_temp = df[k].copy()\n",
    "        df_temp_iqr = iqr(df_temp)\n",
    "        df_temp_std = np.std(df_temp)\n",
    "        df_temp_med= np.median(df_temp)\n",
    "        df_temp_q1=np.percentile(df_temp , 25)\n",
    "        df_temp_q3=np.percentile(df_temp , 75)\n",
    "        df_temp_lower = df_temp_q1-1.5*df_temp_iqr\n",
    "        df_temp_upper = df_temp_q3+2*df_temp_iqr\n",
    "        #df[k].fillna(df[k].median(),inplace=True)    \n",
    "        df[k].loc[df_temp > df_temp_upper]=np.percentile(df_temp, q = 99.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料最大最小化\n",
    "#df = MinMaxScaler().fit_transform(df)\n",
    "#將資料標準化\n",
    "df = StandardScaler().fit_transform(df)\n",
    "\n",
    "# 將前述轉換完畢資料 df , 重新切成 train_X, test_X\n",
    "train_num = train_Y.shape[0]\n",
    "train_X = pd.DataFrame(df[:train_num])\n",
    "test_X = pd.DataFrame(df[train_num:])\n",
    "\n",
    "train_Y = pd.DataFrame(train_Y.map(lambda x :int(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 切分數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "result=next(kf.split(train_X), None)\n",
    "train=train_X.iloc[result[0]]\n",
    "valid=train_X.iloc[result[1]]\n",
    "df_train=train\n",
    "df_train_Y=train_Y.iloc[result[0]]\n",
    "df_valid=valid\n",
    "df_valid_Y=train_Y.iloc[result[1]]\n",
    "\n",
    "df_train, df_valid, df_train_Y,df_valid_Y = train_test_split(train_X, train_Y,\\\n",
    "test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型 : 邏輯斯迴歸 / Lasso / Ridge / 梯度提升 / 隨機森林\n",
    "from sklearn.linear_model import LogisticRegression,Ridge,Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "t = lambda x :1 if x >1 else x\n",
    "def tra(y):\n",
    "    for i in range(len(y)):\n",
    "        y[i]=t(y[i])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "param = {'max_depth':5, 'eta':1, 'objective':'binary:logistic', 'alpha': 0.0001, 'lambda': 1}\n",
    "num_round = 15\n",
    "dtrain = xgb.DMatrix(df_train,label=df_train_Y)\n",
    "xgbst = xgb.train(param, dtrain, num_round)\n",
    "\n",
    "dval= xgb.DMatrix(df_valid,label=df_valid_Y)\n",
    "\n",
    "xgbst_predval = xgbst.predict(dval)\n",
    "validlabel = dval.get_label()\n",
    "AUC = metrics.roc_auc_score(validlabel,xgbst_predval)\n",
    "print(AUC)\n",
    "# make prediction\n",
    "dtrain = xgb.DMatrix(train_X,label=train_Y)\n",
    "xgbst = xgb.train(param, dtrain, num_round)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "xgbst_preds = xgbst.predict(dtest)\n",
    "print(xgbst_preds)\n",
    "sub = pd.DataFrame({'name': name, 'poi': xgbst_preds})\n",
    "print(sub)\n",
    "#sub.to_csv('Enron_xgboost.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=.3)\n",
    "\n",
    "###########train###########\n",
    "ridge.fit(df_train,df_train_Y)\n",
    "###########valid###########\n",
    "ridge_predval =ridge.predict(df_valid).reshape(23)\n",
    "print(ridge_predval)\n",
    "AUC = metrics.roc_auc_score(df_valid_Y, ridge_predval)\n",
    "print(AUC)\n",
    "\n",
    "###########tset###########\n",
    "#ridge.fit(train_X, train_Y)\n",
    "ridge_pred = abs(ridge.predict(test_X)).reshape(33)\n",
    "\n",
    "sub = pd.DataFrame({'name': name, 'poi': ridge_pred})\n",
    "print(sub)\n",
    "#sub.to_csv('Enron_ridge.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.01)\n",
    "###########train###########\n",
    "lasso.fit(df_train,df_train_Y)\n",
    "###########valid###########\n",
    "lasso_predval = tra(abs(lasso.predict(df_valid)))\n",
    "AUC=metrics.roc_auc_score(df_valid_Y, lasso_predval)\n",
    "print(AUC)\n",
    "###########tset###########\n",
    "#lasso = Lasso(alpha=0.001)\n",
    "#lasso.fit(train_X, train_Y)\n",
    "lasso_pred = abs(lasso.predict(test_X))\n",
    "sub = pd.DataFrame({'name': name, 'poi': tra(lasso_pred)})\n",
    "print(sub)\n",
    "#sub.to_csv('Enron_lasso.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度提升機預測檔 \n",
    "gdbt = GradientBoostingRegressor(tol=0.1, subsample=0.37, n_estimators=500, #max_features=20, \n",
    "                                 max_depth=8, learning_rate=0.01)\n",
    "###########train###########\n",
    "gdbt.fit(df_train,df_train_Y)\n",
    "###########valid###########\n",
    "gdbt_predval = tra(abs(gdbt.predict(df_valid)))\n",
    "AUC=metrics.roc_auc_score(df_valid_Y, gdbt_predval)\n",
    "print(AUC)\n",
    "\n",
    "###########tset###########\n",
    "gdbt.fit(train_X, train_Y)\n",
    "gdbt_pred = abs(gdbt.predict(test_X))\n",
    "\n",
    "sub = pd.DataFrame({'name': name, 'poi': tra(gdbt_pred)})\n",
    "#print(sub)\n",
    "#sub.to_csv('Enron_gdbt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機森林預測檔 \n",
    "rf = RandomForestRegressor(n_estimators=200, min_samples_split=8, min_samples_leaf=10,#max_features='', \n",
    "                           max_depth=6, bootstrap=False)\n",
    "###########train###########\n",
    "rf.fit(df_train,df_train_Y)\n",
    "###########validation###########\n",
    "rf_predval = abs(rf.predict(df_valid))\n",
    "AUC=metrics.roc_auc_score(df_valid_Y, rf_predval)\n",
    "print(AUC)\n",
    "###########test###########\n",
    "rf.fit(train_X, train_Y)\n",
    "rf_pred = abs(rf.predict(test_X))\n",
    "sub = pd.DataFrame({'name': name, 'poi': tra((rf_pred))})\n",
    "#print(sub)\n",
    "#sub.to_csv('Enron_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_r=LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0)\n",
    "log_r.fit(df_train,df_train_Y)\n",
    "log_r_predval = abs(log_r.predict_proba(df_valid))\n",
    "log_r_pred=[]\n",
    "for i,p in enumerate(log_r_predval):\n",
    "    log_r_pred.append(log_r_predval[i][1])\n",
    "log_r_pred=np.array(log_r_pred)\n",
    "print(log_r_pred)\n",
    "AUC=metrics.roc_auc_score(df_valid_Y, log_r_pred)\n",
    "print(AUC)\n",
    "###########test###########\n",
    "log_r=LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0)\n",
    "log_r.fit(train_X, train_Y)\n",
    "log_r_pred=log_r.predict_proba(test_X)\n",
    "print(log_r_pred)\n",
    "pred=[]\n",
    "for i,p in enumerate(log_r_pred):\n",
    "    pred.append(log_r_pred[i][1])\n",
    "pred=np.array(pred)\n",
    "sub = pd.DataFrame({'name': name, 'poi':pred})\n",
    "print(sub)\n",
    "#sub.to_csv('Enron_logistic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混合泛化預測\n",
    "blending_pred = ridge_pred*0.05+ rf_pred*0.75+xgbst_preds*0.2\n",
    "sub = pd.DataFrame({'name': name, 'poi':tra(blending_pred)})\n",
    "#sub['poi'] = sub['poi'].map(lambda x:True if x>0.5 else False) \n",
    "print(sub)\n",
    "#sub.to_csv('rf-xgbst-ridge.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
